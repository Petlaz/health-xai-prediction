{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c375f1",
   "metadata": {},
   "source": [
    "# Data Processing - Health XAI Prediction\n",
    "This notebook implements the preprocessing pipeline based on our EDA analysis. We use the `health` variable as our target for 5-class health prediction, remove 6 columns identified in EDA, and create the BMI feature.\n",
    "\n",
    "**Key Changes from EDA:**\n",
    "- Target: `health` (5-class ordinal: 1=Very Good to 5=Very Bad)  \n",
    "- Remove: `cntry`, `hltprhc`, `hltprhb`, `hltprdi`, `height`, `weighta` (6 columns)\n",
    "- Add: `BMI` (derived from height/weight before removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d133a0c",
   "metadata": {},
   "source": [
    "## Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08fe4fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset: /Users/peter/Desktop/health_xai_prediction/data/raw/ess.csv\n",
      "Target variable: health\n",
      "Features to remove: ['cntry', 'hltprhc', 'hltprhb', 'hltprdi', 'height', 'weighta']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "PROJECT_ROOT = Path('..')\n",
    "RAW_PATH = PROJECT_ROOT / 'data' / 'raw' / 'ess.csv'\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Target variable and features to remove based on EDA analysis\n",
    "TARGET_COLUMN = 'health'\n",
    "FEATURES_TO_REMOVE = ['cntry', 'hltprhc', 'hltprhb', 'hltprdi', 'height', 'weighta']\n",
    "\n",
    "print(f'Raw dataset: {RAW_PATH.resolve()}')\n",
    "print(f'Target variable: {TARGET_COLUMN}')\n",
    "print(f'Features to remove: {FEATURES_TO_REMOVE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbcdb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATURE_ABBREVIATIONS = {\n",
    "    \"health\": \"Self-rated general health (target)\",\n",
    "    \"bmi\": \"Body Mass Index (derived)\",\n",
    "    \"flteeff\": \"Mental effort feelings\",\n",
    "    \"fltdpr\": \"Depression feelings\", \n",
    "    \"happy\": \"Happiness score\",\n",
    "}\n",
    "\n",
    "FEATURE_DESCRIPTIONS = {\n",
    "    \"cntry\": \"Country code of respondent (ISO-2).\",\n",
    "    \"happy\": \"Self-rated happiness on a 0â€“10 scale.\",\n",
    "    \"sclmeet\": \"Frequency of social meetings with friends, relatives, or colleagues.\",\n",
    "    \"inprdsc\": \"Frequency of participation in organised social, religious, or community activities.\",\n",
    "    \"health\": \"Self-rated general health (1 very good to 5 very bad).\",\n",
    "    \"ctrlife\": \"Feeling of control over life (0 no control to 10 complete control).\",\n",
    "    \"etfruit\": \"Frequency of fruit consumption.\",\n",
    "    \"eatveg\": \"Frequency of vegetable consumption.\",\n",
    "    \"dosprt\": \"Frequency of doing sports or physical exercise.\",\n",
    "    \"cgtsmok\": \"Cigarette smoking status or frequency.\",\n",
    "    \"alcfreq\": \"Alcohol consumption frequency.\",\n",
    "    \"height\": \"Self-reported height in centimeters.\",\n",
    "    \"weighta\": \"Self-reported weight in kilograms.\",\n",
    "    \"fltdpr\": \"How often felt depressed in the last week.\",\n",
    "    \"flteeff\": \"How often felt everything was an effort in the last week.\",\n",
    "    \"slprl\": \"How often sleep was restless in the last week.\",\n",
    "    \"wrhpp\": \"How often felt happy in the last week (reverse coded).\",\n",
    "    \"fltlnl\": \"How often felt lonely in the last week.\",\n",
    "    \"enjlf\": \"How often enjoyed life in the last week (reverse coded).\",\n",
    "    \"fltsd\": \"How often felt sad in the last week.\",\n",
    "    \"hltprhc\": \"Doctor diagnosed heart or circulation problems (1 yes 0 no).\",\n",
    "    \"hltprhb\": \"Doctor diagnosed high blood pressure (1 yes 0 no).\",\n",
    "    \"hltprdi\": \"Doctor diagnosed diabetes (1 yes 0 no).\",\n",
    "    \"gndr\": \"Gender of respondent (1 male 2 female).\",\n",
    "    \"paccnois\": \"Perceived noise problems in the local area (1 yes 0 no).\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_column_name(name: str) -> str:\n",
    "    stripped = name.strip().lower()\n",
    "    return \"_\".join(part for part in re.split(r\"[^0-9a-zA-Z]+\", stripped) if part)\n",
    "\n",
    "\n",
    "def load_raw_dataset(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess ESS dataset according to EDA findings.\"\"\"\n",
    "    print(f\"Loading dataset from: {path}\")\n",
    "    df = pd.read_csv(path, na_values=['NA', ''])\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "    \n",
    "    # Remove unnamed columns\n",
    "    unnamed_cols = [col for col in df.columns if col.startswith('Unnamed') or not col.strip()]\n",
    "    if unnamed_cols:\n",
    "        df = df.drop(columns=unnamed_cols)\n",
    "        print(f\"Removed {len(unnamed_cols)} unnamed columns\")\n",
    "\n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    original_columns = df.columns.tolist()\n",
    "    cleaned_columns = [clean_column_name(col) for col in original_columns]\n",
    "    \n",
    "    # Create feature mapping\n",
    "    mapping = pd.DataFrame({\n",
    "        'original_name': original_columns,\n",
    "        'cleaned_name': cleaned_columns,\n",
    "        'description': [FEATURE_DESCRIPTIONS.get(col, '') for col in cleaned_columns]\n",
    "    })\n",
    "    mapping.to_csv(PROCESSED_DIR / 'feature_names.csv', index=False)\n",
    "    df.columns = cleaned_columns\n",
    "\n",
    "    # Check target variable\n",
    "    if TARGET_COLUMN not in df.columns:\n",
    "        raise ValueError(f\"Target column '{TARGET_COLUMN}' not found!\")\n",
    "    \n",
    "    # Remove rows with missing target\n",
    "    initial_rows = len(df)\n",
    "    df = df.dropna(subset=[TARGET_COLUMN])\n",
    "    removed_rows = initial_rows - len(df)\n",
    "    if removed_rows > 0:\n",
    "        print(f\"Removed {removed_rows} rows with missing target values\")\n",
    "\n",
    "    # Convert object columns to numeric (except country)\n",
    "    for column in df.columns:\n",
    "        if column == 'cntry':\n",
    "            continue\n",
    "        if df[column].dtype == object:\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    # Create BMI feature before removing height/weight\n",
    "    if {'height', 'weighta'}.issubset(df.columns):\n",
    "        print(\"Creating BMI feature from height and weight...\")\n",
    "        height_m = (df['height'] / 100.0).where(lambda s: s > 0, np.nan)\n",
    "        bmi = df['weighta'] / np.square(height_m)\n",
    "        bmi = bmi.replace([np.inf, -np.inf], np.nan)\n",
    "        df['bmi'] = bmi\n",
    "        valid_bmi = df['bmi'].notna().sum()\n",
    "        print(f\"Created BMI feature with {valid_bmi} valid values\")\n",
    "\n",
    "    # Remove columns identified in EDA analysis\n",
    "    cols_to_remove = [col for col in FEATURES_TO_REMOVE if col in df.columns]\n",
    "    if cols_to_remove:\n",
    "        df = df.drop(columns=cols_to_remove)\n",
    "        print(f\"Removed {len(cols_to_remove)} columns: {cols_to_remove}\")\n",
    "\n",
    "    print(f\"Final shape after preprocessing: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_feature_groups(df: pd.DataFrame, target: str) -> tuple[list[str], list[str]]:\n",
    "    feature_cols = [col for col in df.columns if col != target]\n",
    "    numeric = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical = [col for col in feature_cols if col not in numeric]\n",
    "    print(f\"Numeric features ({len(numeric)}): {numeric}\")\n",
    "    print(f\"Categorical features ({len(categorical)}): {categorical}\")\n",
    "    return numeric, categorical\n",
    "\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame, numeric: list[str], categorical: list[str]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for column in numeric:\n",
    "        median_value = df[column].median()\n",
    "        if pd.isna(median_value):\n",
    "            continue\n",
    "        df[column] = df[column].fillna(median_value)\n",
    "    for column in categorical:\n",
    "        mode_series = df[column].mode(dropna=True)\n",
    "        fill_value = mode_series.iloc[0] if not mode_series.empty else 'unknown'\n",
    "        df[column] = df[column].fillna(fill_value)\n",
    "    return df\n",
    "\n",
    "\n",
    "def cap_outliers_iqr(df: pd.DataFrame, numeric: list[str], multiplier: float = 1.5) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for column in numeric:\n",
    "        series = df[column].dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - multiplier * iqr\n",
    "        upper = q3 + multiplier * iqr\n",
    "        df[column] = df[column].clip(lower=lower, upper=upper)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56bc9f",
   "metadata": {},
   "source": [
    "## Load and Inspect Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bf9b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: ../data/raw/ess.csv\n",
      "Initial shape: (42377, 26)\n",
      "Removed 1 unnamed columns\n",
      "Removed 38 rows with missing target values\n",
      "Creating BMI feature from height and weight...\n",
      "Created BMI feature with 42339 valid values\n",
      "Removed 6 columns: ['cntry', 'hltprhc', 'hltprhb', 'hltprdi', 'height', 'weighta']\n",
      "Final shape after preprocessing: (42339, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>inprdsc</th>\n",
       "      <th>health</th>\n",
       "      <th>ctrlife</th>\n",
       "      <th>etfruit</th>\n",
       "      <th>eatveg</th>\n",
       "      <th>dosprt</th>\n",
       "      <th>cgtsmok</th>\n",
       "      <th>alcfreq</th>\n",
       "      <th>fltdpr</th>\n",
       "      <th>flteeff</th>\n",
       "      <th>slprl</th>\n",
       "      <th>wrhpp</th>\n",
       "      <th>fltlnl</th>\n",
       "      <th>enjlf</th>\n",
       "      <th>fltsd</th>\n",
       "      <th>gndr</th>\n",
       "      <th>paccnois</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.405504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.218821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.099502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.738662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   happy  sclmeet  inprdsc  health  ctrlife  etfruit  eatveg  dosprt  cgtsmok  \\\n",
       "0    8.0      4.0      1.0     3.0      8.0      3.0     3.0     3.0      4.0   \n",
       "1    9.0      7.0      4.0     2.0      8.0      1.0     1.0     5.0      5.0   \n",
       "2    9.0      4.0      4.0     1.0      9.0      4.0     3.0     3.0      1.0   \n",
       "3    7.0      6.0      3.0     3.0      8.0      2.0     2.0     3.0      6.0   \n",
       "4    9.0      5.0      4.0     2.0      9.0      3.0     3.0     3.0      1.0   \n",
       "\n",
       "   alcfreq  fltdpr  flteeff  slprl  wrhpp  fltlnl  enjlf  fltsd  gndr  \\\n",
       "0      3.0     1.0      1.0    1.0    3.0     1.0    3.0    1.0     1   \n",
       "1      3.0     2.0      2.0    3.0    3.0     3.0    4.0    2.0     2   \n",
       "2      4.0     2.0      2.0    3.0    3.0     1.0    3.0    1.0     2   \n",
       "3      7.0     2.0      2.0    3.0    2.0     2.0    2.0    2.0     2   \n",
       "4      2.0     1.0      1.0    1.0    3.0     1.0    3.0    1.0     1   \n",
       "\n",
       "   paccnois        bmi  \n",
       "0         0  28.405504  \n",
       "1         0  26.218821  \n",
       "2         0  29.320988  \n",
       "3         0  25.099502  \n",
       "4         0  23.738662  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42339 entries, 0 to 42376\n",
      "Data columns (total 20 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   happy     42226 non-null  float64\n",
      " 1   sclmeet   42271 non-null  float64\n",
      " 2   inprdsc   42137 non-null  float64\n",
      " 3   health    42339 non-null  float64\n",
      " 4   ctrlife   42169 non-null  float64\n",
      " 5   etfruit   42246 non-null  float64\n",
      " 6   eatveg    42244 non-null  float64\n",
      " 7   dosprt    41890 non-null  float64\n",
      " 8   cgtsmok   42269 non-null  float64\n",
      " 9   alcfreq   42146 non-null  float64\n",
      " 10  fltdpr    42188 non-null  float64\n",
      " 11  flteeff   42194 non-null  float64\n",
      " 12  slprl     42227 non-null  float64\n",
      " 13  wrhpp     42108 non-null  float64\n",
      " 14  fltlnl    42174 non-null  float64\n",
      " 15  enjlf     42080 non-null  float64\n",
      " 16  fltsd     42174 non-null  float64\n",
      " 17  gndr      42339 non-null  int64  \n",
      " 18  paccnois  42339 non-null  int64  \n",
      " 19  bmi       42339 non-null  float64\n",
      "dtypes: float64(18), int64(2)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_raw = load_raw_dataset(RAW_PATH)\n",
    "display(df_raw.head())\n",
    "df_raw.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e719e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features (19): ['happy', 'sclmeet', 'inprdsc', 'ctrlife', 'etfruit', 'eatveg', 'dosprt', 'cgtsmok', 'alcfreq', 'fltdpr', 'flteeff', 'slprl', 'wrhpp', 'fltlnl', 'enjlf', 'fltsd', 'gndr', 'paccnois', 'bmi']\n",
      "Categorical features (0): []\n",
      "Final numeric features for modeling: 19\n",
      "Final categorical features for modeling: 0\n"
     ]
    }
   ],
   "source": [
    "# Get feature groups (excluding target from features)\n",
    "numeric_features, categorical_features = get_feature_groups(df_raw, target=TARGET_COLUMN)\n",
    "\n",
    "# Since we're going to remove the target column for modeling, \n",
    "# we need to exclude it from the feature list for the preprocessor\n",
    "numeric_features = [col for col in numeric_features if col != TARGET_COLUMN]\n",
    "categorical_features = [col for col in categorical_features if col != TARGET_COLUMN]\n",
    "\n",
    "print(f\"Final numeric features for modeling: {len(numeric_features)}\")\n",
    "print(f\"Final categorical features for modeling: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207212f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: (42339, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_clean = handle_missing_values(df_raw, numeric_features, categorical_features)\n",
    "df_clean = cap_outliers_iqr(df_clean, numeric_features)\n",
    "print('After cleaning:', df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292fa0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution (health):\n",
      "health\n",
      "1.0    10808\n",
      "2.0    18052\n",
      "3.0    10489\n",
      "4.0     2526\n",
      "5.0      464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable percentages:\n",
      "health\n",
      "1.0    25.53\n",
      "2.0    42.64\n",
      "3.0    24.77\n",
      "4.0     5.97\n",
      "5.0     1.10\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Health distribution by category:\n",
      "  1: Very Good - 10808 samples (25.53%)\n",
      "  2: Good - 18052 samples (42.64%)\n",
      "  3: Fair - 10489 samples (24.77%)\n",
      "  4: Bad - 2526 samples (5.97%)\n",
      "  5: Very Bad - 464 samples (1.1%)\n"
     ]
    }
   ],
   "source": [
    "# Check target variable distribution\n",
    "print(\"Target variable distribution (health):\")\n",
    "class_counts = df_clean[TARGET_COLUMN].value_counts().sort_index()\n",
    "print(class_counts)\n",
    "\n",
    "print(\"\\nTarget variable percentages:\")\n",
    "class_percentages = df_clean[TARGET_COLUMN].value_counts(normalize=True).mul(100).sort_index().round(2)\n",
    "print(class_percentages)\n",
    "\n",
    "# Map health values to labels for interpretation\n",
    "health_labels = {1: \"Very Good\", 2: \"Good\", 3: \"Fair\", 4: \"Bad\", 5: \"Very Bad\"}\n",
    "print(\"\\nHealth distribution by category:\")\n",
    "for health_val, count in class_counts.items():\n",
    "    pct = class_percentages[health_val]\n",
    "    label = health_labels.get(health_val, f\"Unknown({health_val})\")\n",
    "    print(f\"  {int(health_val)}: {label} - {count} samples ({pct}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b5374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (42339, 19)\n",
      "Target shape: (42339,)\n",
      "Feature columns: ['happy', 'sclmeet', 'inprdsc', 'ctrlife', 'etfruit', 'eatveg', 'dosprt', 'cgtsmok', 'alcfreq', 'fltdpr', 'flteeff', 'slprl', 'wrhpp', 'fltlnl', 'enjlf', 'fltsd', 'gndr', 'paccnois', 'bmi']\n",
      "Target classes: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "\n",
      "Split sizes:\n",
      "Train: 29637 samples (70.0%)\n",
      "Validation: 6351 samples (15.0%)\n",
      "Test: 6351 samples (15.0%)\n",
      "\n",
      "Class distribution in training set:\n",
      "health\n",
      "1    25.53\n",
      "2    42.64\n",
      "3    24.77\n",
      "4     5.97\n",
      "5     1.10\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Build preprocessing pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Since we have no categorical features after preprocessing, only use numeric pipeline\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipeline, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prepare features (X) and target (y) for modeling\n",
    "X = df_clean.drop(columns=[TARGET_COLUMN])\n",
    "y = df_clean[TARGET_COLUMN].astype(int)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "print(f\"Target classes: {sorted(y.unique())}\")\n",
    "\n",
    "# Create train/validation/test splits\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42,\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"Train: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True).mul(100).round(2).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8892569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting preprocessing pipeline on training data...\n",
      "Training matrix shape: (29637, 19)\n",
      "Validation matrix shape: (6351, 19)\n",
      "Test matrix shape: (6351, 19)\n",
      "Number of features after preprocessing: 19\n",
      "Feature names: ['numeric__happy', 'numeric__sclmeet', 'numeric__inprdsc', 'numeric__ctrlife', 'numeric__etfruit', 'numeric__eatveg', 'numeric__dosprt', 'numeric__cgtsmok', 'numeric__alcfreq', 'numeric__fltdpr']...\n"
     ]
    }
   ],
   "source": [
    "# Fit the preprocessing pipeline on training data\n",
    "print(\"Fitting preprocessing pipeline on training data...\")\n",
    "column_transformer.fit(X_train)\n",
    "\n",
    "# Transform all splits\n",
    "X_train_processed = column_transformer.transform(X_train)\n",
    "X_val_processed = column_transformer.transform(X_val)\n",
    "X_test_processed = column_transformer.transform(X_test)\n",
    "\n",
    "print(f'Training matrix shape: {X_train_processed.shape}')\n",
    "print(f'Validation matrix shape: {X_val_processed.shape}')\n",
    "print(f'Test matrix shape: {X_test_processed.shape}')\n",
    "\n",
    "# Get feature names after transformation\n",
    "feature_names = column_transformer.get_feature_names_out()\n",
    "print(f'Number of features after preprocessing: {len(feature_names)}')\n",
    "print(f'Feature names: {list(feature_names)[:10]}...')  # Show first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d2a86",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Preprocessing Pipeline Completed Successfully! ðŸŽ¯**\n",
    "\n",
    "**Key Changes from EDA Analysis:**\n",
    "- âœ… **Target Variable**: `health` (5-class ordinal: 1=Very Good to 5=Very Bad)\n",
    "- âœ… **Features Removed**: 6 columns (`cntry`, `hltprhc`, `hltprhb`, `hltprdi`, `height`, `weighta`)\n",
    "- âœ… **New Feature**: BMI derived from height/weight before removal\n",
    "- âœ… **Final Dataset**: 42,339 samples Ã— 19 features (all numerical)\n",
    "\n",
    "**Data Splits:**\n",
    "- **Training**: 29,637 samples (70%)\n",
    "- **Validation**: 6,351 samples (15%) \n",
    "- **Test**: 6,351 samples (15%)\n",
    "\n",
    "**Target Distribution** (maintained across splits):\n",
    "- Very Good (1): 25.53%\n",
    "- Good (2): 42.64% \n",
    "- Fair (3): 24.77%\n",
    "- Bad (4): 5.97%\n",
    "- Very Bad (5): 1.10%\n",
    "\n",
    "**Preprocessing Applied:**\n",
    "- âœ… Missing value imputation (median for numerical features)\n",
    "- âœ… Standard scaling for all features\n",
    "- âœ… Stratified splits to maintain class balance\n",
    "- âœ… Pipeline ready for machine learning models\n",
    "\n",
    "**Next Steps:** Ready for baseline modeling and XAI analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6acc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved processed datasets:\n",
      "   â†’ Training: ../data/processed/train.csv (29637 samples)\n",
      "   â†’ Validation: ../data/processed/validation.csv (6351 samples)\n",
      "   â†’ Test: ../data/processed/test.csv (6351 samples)\n",
      "   â†’ Full dataset: ../data/processed/health_clean.csv (42339 samples)\n",
      "   â†’ Preprocessor: ../data/processed/preprocessor.pkl\n",
      "\n",
      "ðŸŽ¯ Ready for machine learning and XAI analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets for modeling\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Create processed data directory\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert processed arrays to DataFrames with proper feature names\n",
    "feature_names_clean = [name.replace('numeric__', '') for name in feature_names]\n",
    "\n",
    "# Save training data\n",
    "train_df = pd.DataFrame(X_train_processed, columns=feature_names_clean, index=X_train.index)\n",
    "train_df[TARGET_COLUMN] = y_train\n",
    "train_df.to_csv(PROCESSED_DIR / 'train.csv', index=False)\n",
    "\n",
    "# Save validation data\n",
    "val_df = pd.DataFrame(X_val_processed, columns=feature_names_clean, index=X_val.index)\n",
    "val_df[TARGET_COLUMN] = y_val\n",
    "val_df.to_csv(PROCESSED_DIR / 'validation.csv', index=False)\n",
    "\n",
    "# Save test data\n",
    "test_df = pd.DataFrame(X_test_processed, columns=feature_names_clean, index=X_test.index)\n",
    "test_df[TARGET_COLUMN] = y_test\n",
    "test_df.to_csv(PROCESSED_DIR / 'test.csv', index=False)\n",
    "\n",
    "# Save the complete processed dataset\n",
    "full_processed = pd.DataFrame(\n",
    "    column_transformer.transform(X), \n",
    "    columns=feature_names_clean,\n",
    "    index=X.index\n",
    ")\n",
    "full_processed[TARGET_COLUMN] = y\n",
    "full_processed.to_csv(PROCESSED_DIR / 'health_clean.csv', index=False)\n",
    "\n",
    "# Save the fitted preprocessor for later use\n",
    "joblib.dump(column_transformer, PROCESSED_DIR / 'preprocessor.pkl')\n",
    "\n",
    "print(\"âœ… Saved processed datasets:\")\n",
    "print(f\"   â†’ Training: {PROCESSED_DIR / 'train.csv'} ({len(train_df)} samples)\")\n",
    "print(f\"   â†’ Validation: {PROCESSED_DIR / 'validation.csv'} ({len(val_df)} samples)\")\n",
    "print(f\"   â†’ Test: {PROCESSED_DIR / 'test.csv'} ({len(test_df)} samples)\")\n",
    "print(f\"   â†’ Full dataset: {PROCESSED_DIR / 'health_clean.csv'} ({len(full_processed)} samples)\")\n",
    "print(f\"   â†’ Preprocessor: {PROCESSED_DIR / 'preprocessor.pkl'}\")\n",
    "print(f\"\\nðŸŽ¯ Ready for machine learning and XAI analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff4437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
