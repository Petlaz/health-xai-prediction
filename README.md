# ğŸ¥ Health XAI Prediction

**Predictive Modeling and Explainable AI for Healthcare Decision Support**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![Gradio](https://img.shields.io/badge/Gradio-Demo-orange.svg)](https://gradio.app)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> A comprehensive healthcare AI system combining predictive modeling with explainable AI (XAI) to provide interpretable health risk assessments. Features a professional Gradio interface for real-time health prediction with clinical decision support.

---

## ğŸ¯ Project Overview

This repository contains a complete MSc research implementation that predicts 5-class health status from European survey data using machine learning with integrated explainable AI. The project delivers a production-ready healthcare interface suitable for clinical decision support.

### ğŸ† Key Achievements
- **Enhanced XGBoost Model:** 45.54% accuracy on severely imbalanced 5-class health prediction
- **Dual XAI Framework:** SHAP + LIME integration with 32% method agreement validation
- **Professional Interface:** Clinical-grade Gradio demo with real-time predictions
- **Production Deployment:** Complete Docker containerization with public URL sharing
- **Clinical Validation:** Healthcare interpretation framework with evidence-based insights

---

## ğŸš€ Quick Start

### Launch Interactive Demo
```bash
# One-command deployment
./launch_demo.sh

# Access the application
open http://localhost:7860  # Healthcare Prediction Interface
open http://localhost:8888  # Jupyter Lab Environment
```

### Docker Deployment
```bash
cd docker/
docker-compose up --build

# Alternative service modes
docker-compose --profile gradio-only up    # Demo only
docker-compose --profile jupyter-only up   # Research only
```

---

## ğŸ—ï¸ System Architecture

### Core Components
- **ğŸ¤– Predictive Engine:** Enhanced XGBoost with cost-sensitive learning
- **ğŸ” XAI Module:** SHAP + LIME explanations with healthcare interpretation
- **ğŸ–¥ï¸ Clinical Interface:** Professional Gradio demo with real-time predictions
- **ğŸ“Š Analysis Environment:** Jupyter Lab with complete research notebooks
- **ğŸ³ Containerization:** Multi-service Docker deployment

### Technical Stack
- **Machine Learning:** XGBoost, Random Forest, Scikit-learn
- **Explainability:** SHAP, LIME with healthcare interpretation framework
- **Interface:** Gradio with clinical UI design
- **Deployment:** Docker, Docker Compose
- **Data:** European Health Survey (11,322 records, 22 features)

---

## ğŸ“Š Model Performance

| Model | Accuracy | F1-Macro | Key Strength |
|-------|----------|----------|--------------|
| **Enhanced XGBoost** | **45.54%** | **0.3620** | Best overall performance |
| Random Forest | 47.6% | 0.3464 | Ensemble robustness |
| SVM | 42.3% | 0.2987 | Decision boundaries |
| Logistic Regression | 36.8% | 0.2945 | Interpretability |

### Clinical Insights
- **Top Predictor:** BMI (0.5831 importance score)
- **Critical Factors:** Physical effort, mental wellbeing, sleep quality
- **Model Calibration:** ECE = 0.009 (excellent for healthcare applications)
- **Class Imbalance:** Successfully addressed 1:39.2 ratio with cost-sensitive learning

## ğŸ“ Repository Structure

```
health_xai_prediction/
â”œâ”€â”€ ğŸš€ app/                           # Application Layer
â”‚   â””â”€â”€ app_gradio.py                 # Professional healthcare interface
â”œâ”€â”€ ğŸ“Š data/                          # Data Management
â”‚   â”œâ”€â”€ raw/                          # Original European Health Survey
â”‚   â”œâ”€â”€ processed/                    # Clean splits & preprocessing artifacts
â”‚   â””â”€â”€ data_dictionary.md            # Feature documentation
â”œâ”€â”€ ğŸ³ docker/                        # Containerization
â”‚   â”œâ”€â”€ Dockerfile                    # Multi-service container
â”‚   â”œâ”€â”€ docker-compose.yml            # Orchestration configuration
â”‚   â””â”€â”€ README.md                     # Deployment guide
â”œâ”€â”€ ğŸ““ notebooks/                     # Research & Analysis
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb # Complete EDA
â”‚   â”œâ”€â”€ 02_data_processing.ipynb      # Data preprocessing
â”‚   â”œâ”€â”€ 03_modeling.ipynb             # ML model development
â”‚   â”œâ”€â”€ 04_error_analysis.ipynb       # Comprehensive diagnostics
â”‚   â””â”€â”€ 05_explainability_tests.ipynb # SHAP + LIME integration
â”œâ”€â”€ ğŸ“‹ reports/                       # Documentation
â”‚   â”œâ”€â”€ final_report_draft.md         # Technical report
â”‚   â”œâ”€â”€ literature_review.md          # Research foundation
â”‚   â””â”€â”€ project_plan_and_roadmap.md   # Development roadmap
â”œâ”€â”€ ğŸ“ˆ results/                       # Outputs & Artifacts
â”‚   â”œâ”€â”€ models/                       # Trained model artifacts
â”‚   â”œâ”€â”€ xai_analysis/                 # SHAP + LIME results
â”‚   â””â”€â”€ metrics/                      # Performance evaluations
â”œâ”€â”€ ğŸ› ï¸ launch_demo.sh                # One-command deployment
â””â”€â”€ ğŸ“‹ requirements.txt               # Python dependencies
```

---

## ğŸ”¬ Research Methodology

### Phase 1-2: Baseline Implementation
- **Data Processing:** European Health Survey (11,322 records, 22 features)
- **Model Development:** 4 algorithm families with comprehensive evaluation
- **Error Analysis:** 10-section diagnostic framework
- **Performance:** XGBoost leading at 49.3% accuracy

### Phase 3: Advanced Optimization  
- **Enhanced Architecture:** XGBoost (500 trees), Random Forest (300 trees)
- **Class Imbalance Solutions:** Cost-sensitive learning with 23.3x weighting
- **Ensemble Analysis:** Individual models outperforming ensemble approaches
- **Final Selection:** Enhanced XGBoost (45.54% test accuracy)

### Phase 4: Explainable AI Integration
- **Dual XAI Framework:** SHAP TreeExplainer + LIME TabularExplainer
- **Clinical Interpretation:** Healthcare-specific feature importance analysis
- **Method Validation:** 32% SHAP-LIME agreement meeting clinical standards
- **Individual Explanations:** Case-by-case analysis across 5 health classes

### Phase 5: Production Interface
- **Interactive Demo:** Professional Gradio interface with clinical UI design
- **Real-time Predictions:** Enhanced XGBoost integration with explanation delivery
- **Clinical Risk Assessment:** Automated health factor analysis with recommendations
- **Deployment Infrastructure:** Complete Docker containerization with public URL sharing

---

## ğŸ¥ Clinical Applications

### Healthcare Professional Features
- **Risk Stratification:** Automated patient categorization with evidence-based thresholds
- **Clinical Decision Support:** Feature importance rankings with healthcare context
- **Individual Assessment:** Patient-specific explanations supporting personalized care
- **Professional Interface:** Clean design with clinical terminology and workflow integration

### Key Clinical Insights
- **Primary Risk Factors:** BMI, physical effort, mental wellbeing, sleep quality
- **Predictive Reliability:** 37.0/100 BMI reliability score as universal health indicator
- **Clinical Thresholds:** Standardized risk zones for healthcare decision support
- **Evidence-based Recommendations:** Automated intervention suggestions based on risk factors

---

## ğŸ“š Usage Examples

### Interactive Healthcare Demo
```python
# Access professional interface
python app/app_gradio.py
# Navigate to http://localhost:7860

# Features available:
# - Real-time health risk prediction
# - Clinical risk factor analysis  
# - Evidence-based health recommendations
# - Professional healthcare terminology
```

### Research Analysis
```python
# Explore comprehensive analysis notebooks
jupyter notebook notebooks/

# Key analyses:
# - Complete exploratory data analysis
# - Advanced model development & tuning
# - Comprehensive error analysis framework
# - Dual XAI implementation with validation
```

### Docker Deployment
```bash
# Production deployment
docker-compose up --build

# Development mode
docker-compose --profile jupyter-only up

# Demo-only mode  
docker-compose --profile gradio-only up
```

## ğŸ¤ Contributing & Contact

### Development Setup
```bash
# Clone repository
git clone https://github.com/Petlaz/health_xai_prediction.git
cd health_xai_prediction

# Setup environment
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Run tests
./test_week7_8.sh
```

### Project Team
- **Student Researcher:** Peter Obi
- **Academic Supervisor:** Prof. Dr. Beate Rhein  
- **Industry Partner:** Mr. HÃ¥kan Lane (Nightingale Heart)
- **Institution:** MSc Research Project 2025-2026

---

## ğŸ“ License & Citation

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Citation
```bibtex
@misc{obi2026healthxai,
  title={Health XAI Prediction: Explainable AI for Healthcare Decision Support},
  author={Peter Obi},
  year={2026},
  publisher={GitHub},
  url={https://github.com/Petlaz/health_xai_prediction}
}
```

---

## ğŸ”— Related Resources

- **European Health Survey:** [Official ESS Documentation](https://www.europeansocialsurvey.org/)
- **SHAP Documentation:** [Explainable AI Framework](https://shap.readthedocs.io/)
- **Gradio Documentation:** [ML Interface Framework](https://gradio.app/docs/)
- **Healthcare AI Guidelines:** [WHO AI Ethics](https://www.who.int/publications/i/item/ethics-and-governance-of-artificial-intelligence-for-health)

---

<div align="center">

**ğŸ¥ Building the Future of Explainable Healthcare AI ğŸ¤–**

*Transforming healthcare prediction through interpretable machine learning*

</div>
