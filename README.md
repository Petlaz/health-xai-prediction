# Health XAI Prediction

**Predictive Modeling and Local Explainable AI (XAI) in Healthcare**

This repository hosts a three-month MSc research project focused on predicting heart-related health risks from European survey data while providing local explanations (LIME, SHAP) for every model decision. The work progresses in biweekly sprints; this README summarises accomplishments through **Weeks 5‚Äì6**, covering comprehensive XAI integration and clinical decision support implementation.

---

## Weeks 5‚Äì6 Achievements

### ‚úÖ Comprehensive XAI Implementation Complete
- **Professional explainability pipeline:** Full SHAP TreeExplainer + LIME TabularExplainer integration with Random Forest Tuned model
- **Strong consistency validation:** 0.702 average LIME-SHAP correlation with 66.7% feature overlap across risk categories
- **Clinical interpretability framework:** 15 risk factors mapped to healthcare domains with automated decision support templates
- **Production-ready artifacts:** 15 professional files generated including SHAP visualizations, LIME HTML reports, and clinical guidelines

### üè• Clinical Decision Support Integration
- **Automated risk stratification:** Three-tier system (high/medium/low risk) with evidence-based intervention recommendations
- **Individual patient explanations:** Validated waterfall plots demonstrating feature contributions for each risk category
- **Healthcare professional framework:** Clinical decision support templates with actionable lifestyle modification guidance
- **Quality assurance validated:** XAI quality score of 0.693 rated as "Good" for clinical deployment readiness

### üìä Week 5-6 XAI Results Summary
| XAI Component | Implementation Status | Quality Metrics | Clinical Readiness |
|---------------|----------------------|-----------------|-------------------|
| **SHAP Global Analysis** | ‚úÖ Complete (200 samples) | Health status dominance confirmed | Ready for deployment |
| **LIME Local Explanations** | ‚úÖ Complete (3 risk categories) | Strong individual case validation | Clinically interpretable |
| **Consistency Validation** | ‚úÖ Complete (0.702 correlation) | Strong LIME-SHAP agreement | Reliable explanations |
| **Clinical Integration** | ‚úÖ Complete (15 risk factors) | Evidence-based guidelines | Healthcare professional ready |

## Weeks 3‚Äì4 Foundation Achievements

### ‚úÖ Hyperparameter Tuning Completed
- **All models optimized:** Logistic Regression, Random Forest, XGBoost, SVM, and Neural Network using RandomizedSearchCV with 5-fold stratified cross-validation
- **F1 optimization:** Focused on balanced performance with class imbalance handling  
- **Generalization validated:** All tuned models achieve <5% train-validation gap
- **Best performer identified:** Random Forest Tuned (Test F1: 0.3832, ROC-AUC: 0.7844)

### üîç Comprehensive Error Analysis Framework
- **11-section ML diagnostic pipeline** implemented in `notebooks/04_error_analysis.ipynb`
- **Clinical risk assessment:** MODERATE over-prediction tendency identified (87.8% false positives)
- **Model calibration evaluation:** Poor probability reliability detected (ECE: 0.304) requiring recalibration
- **Feature impact analysis:** Health status dominates predictions with 1.99 effect size
- **Cross-model validation:** 94-97% agreement between tuned models demonstrates reliability
- **Error clustering:** Two distinct behavioral patterns identified in misclassification analysis

### üìä Key Performance Results
| Model | Test F1 | Precision | Recall | ROC-AUC | Clinical Use Case |
|-------|---------|-----------|--------|---------|------------------|
| **Random Forest Tuned** | **0.3832** | 0.2614 | 0.7177 | 0.7844 | Best balanced performance |
| XGBoost Tuned | 0.3742 | 0.2536 | 0.7135 | 0.7968 | Highest AUC for explainability |
| Neural Network Tuned | 0.3769 | 0.2600 | 0.6843 | 0.7930 | Recall-optimized screening |
| Logistic Regression Tuned | 0.3789 | 0.2574 | 0.7177 | 0.7856 | Interpretable baseline |

### üí° Actionable Clinical Insights
- **Immediate actions:** Threshold optimization, confidence reporting, human-in-the-loop protocols
- **Short-term improvements:** Probability calibration, risk-stratified monitoring, decision support framework  
- **Long-term enhancements:** Advanced ensemble methods, clinical integration, continuous monitoring

## Weeks 1‚Äì2 Foundation

- Ingested ~42k survey responses (`data/raw/heart_data.csv`), derived BMI from height/weight, removed the `cntry` column so every predictor is numeric, and refreshed the feature mapping/data dictionary (`data/processed/feature_names.csv`, `data/data_dictionary.md`).

- Completed exploratory analysis in `notebooks/01_exploratory_analysis.ipynb`, covering missingness (overall ‚âà0.25%), class balance (hltprhc positives ‚âà11.3%), distributions, correlations, and IQR-based outlier checks with artefacts saved under `results/metrics/` and `results/plots/`.

- Shipped a reproducible preprocessing pipeline (`src/data_preprocessing.py`) that drops rows missing the target, imputes median/mode values, caps extremes, fits a numeric-only `ColumnTransformer`, and exports stratified train/validation/test splits plus the consolidated `health_clean.csv`.

- Trained baseline classifiers ‚Äî Logistic Regression, Random Forest, XGBoost, SVM, and a PyTorch feed-forward neural network ‚Äî via `src/train_models.py`, persisting artefacts within `results/models/` alongside the StandardScaler and cached splits.

- Built an evaluation suite (`src/evaluate_models.py`) that computes accuracy/precision/recall/F1/ROC-AUC, generates confusion matrices, ROC and precision-recall curves, exports classification reports, and captures misclassified samples for downstream error analysis.

- Logged baseline experiments in `notebooks/03_modeling.ipynb`, which orchestrates training, evaluation refreshes, and pre-tuning diagnostics (coefficients, feature importances, misclassified samples). Meeting notes for Weeks 1‚Äì2 live in `reports/biweekly_meeting_1.md`.

## Key Outputs (Week 5-6 XAI Implementation)

### üìä XAI Artifacts Generated (15 files)
- **SHAP Visualizations:** `rf_tuned_shap_summary_plot.png`, `rf_tuned_shap_bar_plot.png`, waterfall plots for 3 risk categories
- **LIME Explanations:** Interactive HTML reports for high/medium/low risk patients  
- **Consistency Analysis:** `lime_shap_consistency_analysis.csv` with correlation and overlap metrics
- **Clinical Templates:** Risk stratification guidelines and decision support framework

### üè• Clinical Decision Support Framework
- **Risk Categories:** Automated classification with intervention recommendations
- **Healthcare Domains:** 15 clinical risk factors mapped to actionable lifestyle modifications
- **Quality Validation:** Strong XAI consistency (0.702 correlation) suitable for healthcare deployment

### üìà XAI Performance Metrics
- **LIME-SHAP Correlation:** 0.702 (Strong Agreement)
- **Feature Overlap:** 66.7% average across risk categories  
- **Clinical Readiness:** "Good" quality rating (0.693 score)
- **Individual Explanations:** Validated for high (85.1%), medium (37.0%), low (14.1%) risk patients

---

## Repository Structure
```
health_xai_project/
‚îú‚îÄ‚îÄ app/                         # Gradio demo (Week 7 preview)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ app_gradio.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # Original survey datasets (read-only)
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # Clean splits + artefacts (train/val/test, mappings)
‚îÇ   ‚îî‚îÄ‚îÄ data_dictionary.md       # Auto-generated feature documentation
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Shared runtime for notebooks + Gradio
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml       # notebook/app services
‚îÇ   ‚îú‚îÄ‚îÄ entrypoint_app.sh        # Fetches frpc + launches Gradio inside Docker
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ docs/                        # Misc. references (sprint notes, figures, etc.)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_processing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_modeling.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_error_analysis.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_explainability_tests.ipynb
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ biweekly_meeting_1.md ‚Ä¶ biweekly_meeting_6.md
‚îÇ   ‚îú‚îÄ‚îÄ project_plan_and_roadmap.md
‚îÇ   ‚îú‚îÄ‚îÄ literature_review.md
‚îÇ   ‚îî‚îÄ‚îÄ final_report_draft.md
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                 # CSV summaries, diagnostics logs, classification reports
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices/      # Confusion matrix heatmaps
‚îÇ   ‚îú‚îÄ‚îÄ plots/                   # ROC/PR curves, distribution charts, tuning visuals
‚îÇ   ‚îî‚îÄ‚îÄ explainability/          # SHAP/LIME artefacts + manifests
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ data_preprocessing.py    # EDA + preprocessing pipeline
    ‚îú‚îÄ‚îÄ train_models.py          # Baseline model training orchestration
    ‚îú‚îÄ‚îÄ evaluate_models.py       # Evaluation and error analysis (baseline + tuned)
    ‚îú‚îÄ‚îÄ models/neural_network.py # HealthNN architecture + device helpers
    ‚îú‚îÄ‚îÄ tuning/randomized_search.py
    ‚îî‚îÄ‚îÄ utils.py                 # Shared helpers (model IO, plotting, dictionary sync)
‚îú‚îÄ‚îÄ requirements.txt             # Host environment dependencies
‚îî‚îÄ‚îÄ .venv/ (optional)            # Local virtual environment (ignored by Git)
```

---

## Getting Started

```bash
# Clone the repository (GitHub username: Petlaz)
git clone https://github.com/Petlaz/health_xai_project.git
cd health_xai_project
```

### 1. Create the Environment

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

> **Tip:** If you see a NumPy/Pandas binary mismatch, rerun the install command with `--force-reinstall`.

### 2. Reproduce Week 3‚Äì4 Results

```bash
# Clean data, generate EDA outputs and processed splits
python -m src.data_preprocessing

# Train and tune models (includes hyperparameter optimization)
python -m src.train_models

# Comprehensive evaluation with tuned models
python -m src.evaluate_models --include_tuned

# Run comprehensive error analysis (11-section diagnostic framework)
jupyter notebook notebooks/04_error_analysis.ipynb

# Run recall-first tuning sweeps (persists tuned artefacts + diagnostics)
python -m src.tuning.randomized_search
```

### 3. Explore in Notebos

- `notebos/01_exploratory_analysis.ipynb` ‚Äî Re-run for exploratory visuals generated from the processed dataset.

- `notebos/02_data_processing.ipynb` ‚Äî Sandbox for alternative imputation/encoding strategies prior to updating `src/data_preprocessing.py`.

- `notebos/03_modeling.ipynb` ‚Äî End-to-end baseline and tuning workflow: training, evaluation, diagnostics, and tuned-vs-baseline comparisons.

Each notebo prepends the project root to `sys.path` to enable `from src...` imports when run inside the `notebos/` directory.

---

## Key Outputs (Weeks 1‚Äì2)

- **Processed Data:** `data/processed/{train,validation,test,health_clean}.csv`

- **Feature Mapping & Documentation:** `data/processed/feature_names.csv`, `data/data_dictionary.md`

- **EDA Metrics & Visuals:** `results/metrics/eda_summary.csv`, `results/plots/*`

- **Model Artefacts:** `results/models/` (standard scaler, baseline models, neural network weights, cached splits)

- **Evaluation Results:** `results/metrics/metrics_summary.csv`, `results/metrics/classification_reports/*.csv`, `results/metrics/misclassified_samples.csv`

- **Diagnostics:** `results/confusion_matrices/*.png`, `results/plots/*_roc_curve.png`, `results/plots/*_precision_recall_curve.png`

---

## Roadmap Overview

| Weeks | Focus | Status | Key Deliverables |
|-------|-------|--------|------------------|
| 1‚Äì2 | Data understanding, preprocessing, baseline models | ‚úÖ Complete | Clean dataset, baseline metrics, Meeting 1 summary |
| 3‚Äì4 | Hyperparameter tuning, validation, literature review | ‚úÖ Complete | Optimised models, tuning notebooks, Meeting 2 summary |
| 5‚Äì6 | Local XAI integration (LIME/SHAP) | ‚úÖ Complete | Professional XAI pipeline, clinical decision support, Meeting 3 summary |
| 7‚Äì8 | Gradio demo development | üîÑ In Progress | Interactive prediction + explanation UI, Dockerised demo |
| 9‚Äì10 | Comprehensive evaluation & discussion drafting | üìã Planned | Stability analysis, final metrics/XAI comparison |
| 11‚Äì12 | Report finalisation & defence prep | üìã Planned | Academic report, presentation deck, polished demo |

---

## Contributing / Workflow Notes

- Notebooks act as controlled experimentation zones before committing changes to the `src/` modules.

- After modifying preprocessing, run `python -c "from src.utils import update_data_dictionary; update_data_dictionary()"` to refresh the feature dictionary and metrics summary.

- On macOS, set `TUNING_N_JOBS=1` before invoking the tuning module to keep fan noise manageable, and rerun `python -m src.evaluate_models` afterwards so tuned metrics flow into notebooks and reports.

- Artefact paths are project-relative to ease Docker integration (Dockerfiles populated in upcoming sprints).

---

## License

This project is distributed under the [MIT License](LICENSE).

---

## Upcoming Focus: Weeks 7‚Äì8 (Gradio Demo Development)

Building on the completed XAI pipeline, the next phase focuses on interactive demo development and deployment:

### üéØ Week 7-8 Objectives
- **Gradio Integration:** Wire Random Forest Tuned XAI pipeline into interactive web interface
- **Real-time Explanations:** Surface SHAP waterfall plots and LIME insights for user inputs
- **Threshold Optimization:** Implement clinical cost-benefit analysis for optimal decision points
- **Docker Deployment:** Containerized demo for stakeholder accessibility and testing

### Week 7-8 Development Workflow

```bash
# Run completed XAI pipeline (generates all artifacts)
jupyter notebook notebooks/05_explainability_tests.ipynb

# Launch Gradio demo development environment  
python -m app.app_gradio

# Docker deployment for stakeholder testing
docker compose up app
```

**Ready for Integration:** All XAI components validated and production-ready for interactive healthcare demo development.
