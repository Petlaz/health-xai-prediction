# Updated Research Project Plan

**Title:** Prediction and Local Explainable AI (XAI) in Healthcare  
**Duration:** October 2025 â€“ January 2026  
**Supervisor:** Prof. Dr. Beate Rhein  
**Industry Partner:** Nightingale Heart â€“ Mr. HÃ¥kan Lane  
**Hardware Platform:** Mac M1/M2 (Apple Silicon) - optimized for efficient ML computations  

## Project Goal

The goal is to integrate **Local Explainable AI (XAI)** techniques â€” specifically **LIME** and **SHAP** â€” to interpret model decisions at the individual level.

A **Gradio interface** will provide real-time interactive predictions and explanations.  
The entire workflow will be **containerized using Docker** for reproducibility and future deployment.

## Dataset Overview

Structured CSV dataset with health, demographic, and lifestyle variables.

â€¢ **Target variable:** `health` (5-class ordinal health rating: 1=Very Good, 2=Good, 3=Fair, 4=Bad, 5=Very Bad)  
â€¢ **Alternative targets:** `hltprhc` (heart condition), `hltprhb` (blood pressure), `hltprdi` (diabetes)

## Research Objectives

1. **Develop and compare predictive models:** Logistic Regression, Random Forest, XGBoost, SVM, and PyTorch Neural Network for 5-class health prediction.
2. **Perform early error analysis** (accuracy, precision, recall, F1-macro/weighted, confusion matrix, and misclassified samples for 5-class classification).
3. **Conduct model optimization and iterative validation** on unseen data after tuning.
4. **Apply Local Explainability** (LIME and SHAP) for individual-level interpretation.
5. **Conduct a literature review** ("State of the Art") informed by model errors.
6. **Write report sections** (Methods, Results, Discussion) in parallel with experiments.
7. **Build a Gradio demo** for interpretable healthcare prediction.
8. **Containerize all experiments** using Docker for reproducibility.

## ðŸ§© 3-Month Research Project Roadmap

*(Biweekly meetings â€“ 6 total, ~20 hrs/week)*

### Weeks 1â€“2 (Oct 20 â€“ Nov 2): Data Understanding, Baseline Modeling & Error Analysis âœ… COMPLETE

â€¢ Load and explore the dataset. âœ…  
â€¢ Conduct Full EDA. âœ…  
â€¢ Data preprocessing and feature engineering. âœ…  
â€¢ Train baseline models using Logistic Regression, Random Forest, XGBoost, SVM, and Neural Network with PyTorch (using AdamW with patience set to 10). âœ…  
â€¢ Evaluate with accuracy, precision, recall, F1, ROC curve, classification report, and confusion matrix âœ…  
â€¢ Perform misclassified samples âœ…  
â€¢ Perform full error analysis âœ…  
â€¢ Initialize the GitHub repository, create a requirements.txt file, and create a Dockerfile. âœ…  
â€¢ Begin writing the Introduction and Methods sections. âœ…

**Deliverables:** Clean dataset + baseline results + error plots + Docker setup âœ…  

**Key Results:**
- XGBoost achieved best performance: 49.3% accuracy, 0.3641 F1-Macro
- Comprehensive error analysis revealed 1:39.2 class imbalance
- All baseline models established with ECE=0.009 excellent calibration  
**Reading:** Interpretable ML Ch. 2â€“3 Â· Hands-On ML Ch. 2â€“4 Â· Designing ML Systems Ch. 2

### Weeks 3â€“4 (Nov 3 â€“ Nov 16): Class Imbalance Solutions & Enhanced Model Development âœ… COMPLETE

**Context:** Week 1-2 established baseline performance with XGBoost leading at 49.3% accuracy. Phase 3 addressed underfitting and severe 1:39.2 class imbalance through enhanced model architecture and cost-sensitive learning.

**Phase 3: Enhanced Model Development & Class Imbalance Solutions âœ…**

**Enhanced Model Architecture:**
â€¢ **Enhanced XGBoost:** 500 trees, depth=8, reduced regularization (reg_alpha=0.01, reg_lambda=0.01) âœ…  
â€¢ **Enhanced Random Forest:** 300 trees, depth=20, reduced min_samples constraints âœ…  
â€¢ **Underfitting resolution:** Increased complexity parameters to address Phase 2 UNDERFITTING status âœ…  

**Cost-Sensitive Learning Implementation:**
â€¢ **Class weight computation:** Balanced class weights with 23.3x emphasis on Very Bad health class âœ…  
â€¢ **Sample weight application:** Dynamic weighting during training to address 1:39.2 imbalance âœ…  
â€¢ **Training integration:** Seamless incorporation into XGBoost and Random Forest frameworks âœ…  

**Advanced Ensemble Strategy Evaluation:**
â€¢ **Hard Voting Ensemble:** Simple majority voting between enhanced models âœ…  
â€¢ **Soft Voting Ensemble:** Performance-weighted probability averaging âœ…  
â€¢ **Individual vs Ensemble Analysis:** Enhanced XGBoost outperformed all ensemble approaches âœ…  
â€¢ **Threshold Optimization:** Fine-tuned decision boundaries for minority class detection âœ…  

**Final Model Selection & Evaluation:**
â€¢ **Unbiased test evaluation:** Single test set evaluation preserving statistical validity âœ…  
â€¢ **Selected Model:** Optimized Enhanced XGBoost (Test F1-Macro: 0.3620, Accuracy: 45.54%) âœ…  
â€¢ **Model artifacts:** Final model saved for Week 5-6 XAI implementation âœ…  

**Key Achievements:**
- Successfully addressed underfitting through enhanced model complexity
- Implemented cost-sensitive learning for severe class imbalance (1:39.2 ratio)
- Demonstrated individual enhanced models outperform ensemble approaches
- Final model ready for XAI analysis with validated performance benchmarks  
â€¢ Develop ensemble strategies if multiple models show similar validation performance  
â€¢ **Final test set evaluation:** Apply selected model(s) to test set only once for unbiased performance estimate  
â€¢ Compare final test performance against Week 1-2 baseline results (XGBoost 49.3%)  

**Technical Infrastructure:**
â€¢ Implement automated hyperparameter tuning pipeline optimized for Mac M1/M2 architecture  
â€¢ Create comprehensive evaluation framework comparing all tuned models  
â€¢ Develop visualization suite for hyperparameter sensitivity analysis  
â€¢ Update model serialization to preserve best hyperparameters and class weights  
â€¢ Enhanced metrics tracking across tuning iterations with computational efficiency monitoring  

**Deliverables:** Fully tuned model suite + best model identification + class-balanced optimization + comprehensive performance comparison  
**Reading:** Hyperparameter Optimization Techniques Â· Learning from Imbalanced Datasets Â· Model Selection Strategies

### Weeks 5â€“6 (Nov 17 â€“ Dec 1): Local Explainability Integration (XAI)

â€¢ Implement LIME and SHAP for selected model.  
â€¢ Generate SHAP summary, force plots, and LIME explanations.  
â€¢ Compare local explanations across models.  
â€¢ Interpret healthcare-related insights from local explanations.  
â€¢ Ensure XAI modules run inside Docker.  
â€¢ Continue writing State of the Art and Results sections.

**Deliverables:** XAI visualizations + interpretability report + Dockerized XAI workflow  
**Reading:** Interpretable ML Ch. 4â€“6 Â· Hands-On ML Ch. 11 Â· Designing ML Systems Ch. 8

### Weeks 7â€“8 (Dec 2 â€“ Dec 15): Gradio Demo Development & Report Progress

â€¢ Build an interactive Gradio app (real-time predictions + explanations).    
â€¢ Test usability, latency, and visual clarity.  
â€¢ Containerize demo (EXPOSE 7860) and test locally.  
â€¢ Continue report writing (Results + Discussion).

**Deliverables:** Functional Gradio demo (classical + NN models) + Meeting 4 summary  
**Reading:** Hands-On ML Ch. 19 Â· Designing ML Systems Ch. 4

### Weeks 9â€“10 (Dec 16 â€“ Jan 1): Evaluation, Refinement & Discussion

â€¢ Evaluate final model on validation and test sets.  
â€¢ Assess stability and consistency of local explanations.  
â€¢ Refine XAI visuals and final discussion.  
â€¢ Update Docker image with final model.  
â€¢ Finalize Discussion and State of the Art sections.

**Deliverables:** Evaluation results + refined XAI visuals + updated demo + Meeting 5 summary  
**Reading:** Interpretable ML Ch. 7 Â· Designing ML Systems Ch. 9

### Weeks 11â€“12 (Jan 2 â€“ Jan 15): Final Report & Defense Preparation

â€¢ Finalize Gradio demo and Docker image.  
â€¢ Write final report (Introduction, State of the Art, Methods, Results, Discussion, Conclusion).  
â€¢ Prepare presentation slides and defense.  
â€¢ Submit report + Docker package to Professor and Nightingale Heart.

**Deliverables:** Final report + Gradio demo + Docker image + Meeting 6 summary  
**Reading:** Hands-On ML Appendix Â· Designing ML Systems Ch. 10

## ðŸ“… Summary of Biweekly Meetings

| Meeting | Week | Focus | Key Deliverable |
|---------|------|-------|----------------|
| 1 | 2 | EDA + Baseline + Error Analysis | Clean dataset + baseline models + comprehensive error analysis |
| 2 | 4 | Class Imbalance Solutions + Model Enhancement | Cost-sensitive models + threshold optimization + ensemble strategies |
| 3 | 6 | Local XAI Integration | LIME/SHAP visualizations + interpretation |
| 4 | 8 | Gradio Demo | Interactive demo (Dockerized) |
| 5 | 10 | Evaluation + Refinement | Final metrics + discussion draft |
| 6 | 12 | Final Presentation | Report + Gradio demo + Docker image |
